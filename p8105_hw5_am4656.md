p8105_hw5_am4656
================
Aaron Mittel
2022-11-11

# Problem 1

In this problem, we created a dataframe containing data from
participants in the downloaded “data” folder. Each participant’s data is
saved in a separate file within this folder, which can be mapped in
iterative fashion using the read_csv function. A spaghetti plot shows
observations on each subject over time.

![](p8105_hw5_am4656_files/figure-gfm/creating%20study%20data%20dataframe%20from%20files%20in%20data%20folder-1.png)<!-- -->

In general, patients in the experimental group have values that increase
over time. Patients in the control group have values that remain
relatively stable over time.

# Problem 2

This dataframe contains 12 columns which report location, assigned case
id (`uid`), date of homicide, victim demographics, and case outcome
(`disposition`) of homicides from the decade preceding 2018. There are
52179 rows and 50 distinct cities.

*Cities with missing data were removed.*

## *Estimating the Proportion of Unsolved Homicides in Baltimore, MD*

Here, data is presented with the `estimate` of unsolved murders in
Baltimore, MD as well as the associated 95% Confidence Interval
(`conf.low` - `conf.high`).

| estimate | conf.low | conf.high |
|---------:|---------:|----------:|
|     0.65 |     0.63 |      0.66 |

Table 1. Estimate and 95% CI for proportion of murders that are unsolved
in Baltimore, MD

## *Estimating the Proportion of Unsolved Homicides in All Cities in Database*

Here, all cities with data were included in the analysis. Data in the
Table below represents point `estimate`s for the proportion of murders
which went unsolved and the associated 95% Confidence Interval
(`conf.low` - `conf.high`).

| city_state         | estimate | conf.low | conf.high |
|:-------------------|---------:|---------:|----------:|
| Albuquerque, NM    |     0.39 |     0.34 |      0.44 |
| Atlanta, GA        |     0.38 |     0.35 |      0.41 |
| Baltimore, MD      |     0.65 |     0.63 |      0.66 |
| Baton Rouge, LA    |     0.46 |     0.41 |      0.51 |
| Birmingham, AL     |     0.43 |     0.40 |      0.47 |
| Buffalo, NY        |     0.61 |     0.57 |      0.65 |
| Charlotte, NC      |     0.30 |     0.27 |      0.34 |
| Chicago, IL        |     0.74 |     0.72 |      0.75 |
| Cincinnati, OH     |     0.45 |     0.41 |      0.48 |
| Columbus, OH       |     0.53 |     0.50 |      0.56 |
| Dallas, TX         |     0.48 |     0.46 |      0.51 |
| Denver, CO         |     0.54 |     0.48 |      0.60 |
| Detroit, MI        |     0.59 |     0.57 |      0.61 |
| Durham, NC         |     0.37 |     0.31 |      0.43 |
| Fort Worth, TX     |     0.46 |     0.42 |      0.51 |
| Fresno, CA         |     0.35 |     0.31 |      0.39 |
| Houston, TX        |     0.51 |     0.49 |      0.53 |
| Indianapolis, IN   |     0.45 |     0.42 |      0.48 |
| Jacksonville, FL   |     0.51 |     0.48 |      0.54 |
| Kansas City, MO    |     0.41 |     0.38 |      0.44 |
| Las Vegas, NV      |     0.41 |     0.39 |      0.44 |
| Long Beach, CA     |     0.41 |     0.36 |      0.46 |
| Memphis, TN        |     0.32 |     0.30 |      0.34 |
| Miami, FL          |     0.60 |     0.57 |      0.64 |
| Milwaukee, wI      |     0.36 |     0.33 |      0.39 |
| Minneapolis, MN    |     0.51 |     0.46 |      0.56 |
| Nashville, TN      |     0.36 |     0.33 |      0.40 |
| New Orleans, LA    |     0.65 |     0.62 |      0.67 |
| New York, NY       |     0.39 |     0.35 |      0.43 |
| Oklahoma City, OK  |     0.49 |     0.45 |      0.52 |
| Omaha, NE          |     0.41 |     0.37 |      0.46 |
| Philadelphia, PA   |     0.45 |     0.43 |      0.47 |
| Phoenix, AZ        |     0.55 |     0.52 |      0.58 |
| Richmond, VA       |     0.26 |     0.22 |      0.31 |
| Sacramento, CA     |     0.37 |     0.32 |      0.42 |
| San Antonio, TX    |     0.43 |     0.39 |      0.46 |
| San Bernardino, CA |     0.62 |     0.56 |      0.68 |
| San Diego, CA      |     0.38 |     0.34 |      0.43 |
| San Francisco, CA  |     0.51 |     0.47 |      0.55 |
| Savannah, GA       |     0.47 |     0.40 |      0.53 |
| St. Louis, MO      |     0.54 |     0.52 |      0.56 |
| Stockton, CA       |     0.60 |     0.55 |      0.64 |
| Tampa, FL          |     0.46 |     0.39 |      0.53 |
| Tulsa, OK          |     0.33 |     0.29 |      0.37 |
| Washington, DC     |     0.44 |     0.41 |      0.46 |

Table 2. Estimated proportion of unsolved murders (and 95% CI) in each
city with data in the data set

The plot in Figure 1, below, shows the estimates and CIs (y-axis) for
each city (x-axis). Cities have been organized according to the
proportion of unsolved homicides.
![](p8105_hw5_am4656_files/figure-gfm/plot%20w%20estimates%20and%20CIs%20for%20each%20city-1.png)<!-- -->

# Problem 3

This problem uses simulation to explore how power of a 1-sample t-test
changes as sample mean changes during sampling.

First, I generated 5000 datasets from a normal distribution of n = 30
subjects who have sigma = 5 and a mean of 0. I performed a simple t-test
to determine if the sampled mean is significantly different than the
true, set mean of 0 using a de novo function `sim_mean_ttest`. The
figure indicates the outcome of 5000-fold iterative process.
![](p8105_hw5_am4656_files/figure-gfm/sampling%20around%20mean%200-1.png)<!-- -->

Now, repeating this process when sample mean varies from 1 - 6:

![](p8105_hw5_am4656_files/figure-gfm/multiple%20means%20density%20plot-1.png)<!-- -->

The null hypothesis for this t-test is that the difference between the
sample mean and the true mean is 0. When p \< 0.05, we reject the null.

![](p8105_hw5_am4656_files/figure-gfm/p%20rejection%20plot-1.png)<!-- -->

Below, I have made a plot showing the average estimate of sample me on
the y axis and the true mean on the x axis. The smoothed line indicates
comparison among all estimated means while the overlaid points indicate
only means in which the null hypothesis was rejected.

    ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
    ## parametric, : Chernobyl! trL>n 6

    ## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
    ## parametric, : Chernobyl! trL>n 6

    ## Warning in sqrt(sum.squares/one.delta): NaNs produced

    ## Warning in stats::qt(level/2 + 0.5, pred$df): NaNs produced

    ## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning
    ## -Inf

![](p8105_hw5_am4656_files/figure-gfm/comparison%20plot-1.png)<!-- -->

*The average of sample mean for which the null is rejected is
approximately equal to the true value of the mean only when the true
mean is larger than 3. This reflects the influence of the standard
deviation of 5, leading to greater spread in data at smaller mean
values.*
